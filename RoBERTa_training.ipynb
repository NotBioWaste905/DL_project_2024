{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30674,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/guyd1995/lra-benchmarks.git"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-03-24T21:05:14.102198Z",
          "iopub.execute_input": "2024-03-24T21:05:14.102587Z",
          "iopub.status.idle": "2024-03-24T21:05:16.115520Z",
          "shell.execute_reply.started": "2024-03-24T21:05:14.102557Z",
          "shell.execute_reply": "2024-03-24T21:05:16.114405Z"
        },
        "trusted": true,
        "id": "Wmr4JlWCmEuY",
        "outputId": "240762ba-673e-43f3-adb1-9c790c532316"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Cloning into 'lra-benchmarks'...\nremote: Enumerating objects: 154, done.\u001b[K\nremote: Counting objects: 100% (29/29), done.\u001b[K\nremote: Compressing objects: 100% (3/3), done.\u001b[K\nremote: Total 154 (delta 27), reused 26 (delta 26), pack-reused 125\u001b[K\nReceiving objects: 100% (154/154), 29.88 KiB | 7.47 MiB/s, done.\nResolving deltas: 100% (91/91), done.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir datasets"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T21:05:16.117771Z",
          "iopub.execute_input": "2024-03-24T21:05:16.118490Z",
          "iopub.status.idle": "2024-03-24T21:05:17.161728Z",
          "shell.execute_reply.started": "2024-03-24T21:05:16.118455Z",
          "shell.execute_reply": "2024-03-24T21:05:17.160491Z"
        },
        "trusted": true,
        "id": "_zQVVFRhmEub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd datasets"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T21:05:17.163257Z",
          "iopub.execute_input": "2024-03-24T21:05:17.163596Z",
          "iopub.status.idle": "2024-03-24T21:05:17.170885Z",
          "shell.execute_reply.started": "2024-03-24T21:05:17.163566Z",
          "shell.execute_reply": "2024-03-24T21:05:17.169801Z"
        },
        "trusted": true,
        "id": "jZHjrWB1mEub",
        "outputId": "200a78fb-c855-4ab1-a40c-9139d3909af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/working/datasets\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T21:05:17.173893Z",
          "iopub.execute_input": "2024-03-24T21:05:17.174435Z",
          "iopub.status.idle": "2024-03-24T21:05:28.160593Z",
          "shell.execute_reply.started": "2024-03-24T21:05:17.174396Z",
          "shell.execute_reply": "2024-03-24T21:05:28.159506Z"
        },
        "trusted": true,
        "id": "a61P3tVVmEub",
        "outputId": "91d5d143-deef-4fac-c708-9c10a510397c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "--2024-03-24 21:05:18--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\nResolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\nConnecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 84125825 (80M) [application/x-gzip]\nSaving to: 'aclImdb_v1.tar.gz'\n\naclImdb_v1.tar.gz   100%[===================>]  80.23M  6.93MB/s    in 9.6s    \n\n2024-03-24 21:05:28 (8.34 MB/s) - 'aclImdb_v1.tar.gz' saved [84125825/84125825]\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvf aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2024-03-24T21:05:28.162090Z",
          "iopub.execute_input": "2024-03-24T21:05:28.162431Z",
          "iopub.status.idle": "2024-03-24T21:05:36.653403Z",
          "shell.execute_reply.started": "2024-03-24T21:05:28.162399Z",
          "shell.execute_reply": "2024-03-24T21:05:36.651941Z"
        },
        "trusted": true,
        "id": "Hbyncb_9mEub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import glob\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, RobertaModel, AdamW, get_linear_schedule_with_warmup, BertModel, BertTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import time"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T21:05:36.655748Z",
          "iopub.execute_input": "2024-03-24T21:05:36.656213Z",
          "iopub.status.idle": "2024-03-24T21:05:54.799753Z",
          "shell.execute_reply.started": "2024-03-24T21:05:36.656168Z",
          "shell.execute_reply": "2024-03-24T21:05:54.798814Z"
        },
        "trusted": true,
        "id": "AHmWM4LUmEuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neg_files_test = glob.glob('/kaggle/working/datasets/aclImdb/test/neg/*.txt')\n",
        "pos_files_test = glob.glob('/kaggle/working/datasets/aclImdb/test/pos/*.txt')\n",
        "neg_files_train = glob.glob('/kaggle/working/datasets/aclImdb/train/neg/*.txt')\n",
        "pos_files_train = glob.glob('/kaggle/working/datasets/aclImdb/train/pos/*.txt')\n",
        "train_data = []\n",
        "test_data = []\n",
        "for filename in neg_files_train:\n",
        "  with open(filename, 'r', encoding=\"utf-8\") as f:\n",
        "    train_data.append((f.read(), 0))\n",
        "\n",
        "for filename in pos_files_train:\n",
        "  with open(filename, 'r', encoding=\"utf-8\") as f:\n",
        "    train_data.append((f.read(), 1))\n",
        "\n",
        "for filename in neg_files_test:\n",
        "  with open(filename, 'r', encoding=\"utf-8\") as f:\n",
        "    test_data.append((f.read(), 0))\n",
        "\n",
        "\n",
        "for filename in pos_files_test:\n",
        "  with open(filename, 'r', encoding=\"utf-8\") as f:\n",
        "    test_data.append((f.read(), 1))\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T21:05:54.800952Z",
          "iopub.execute_input": "2024-03-24T21:05:54.801419Z",
          "iopub.status.idle": "2024-03-24T21:05:56.710965Z",
          "shell.execute_reply.started": "2024-03-24T21:05:54.801392Z",
          "shell.execute_reply": "2024-03-24T21:05:56.710046Z"
        },
        "trusted": true,
        "id": "00u2MAzHmEuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(test_data)\n",
        "random.shuffle(train_data)\n",
        "test_data = test_data[:len(test_data)//10]\n",
        "train_data = test_data[:len(train_data)//10]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T21:05:56.712220Z",
          "iopub.execute_input": "2024-03-24T21:05:56.712506Z",
          "iopub.status.idle": "2024-03-24T21:05:56.780864Z",
          "shell.execute_reply.started": "2024-03-24T21:05:56.712481Z",
          "shell.execute_reply": "2024-03-24T21:05:56.779848Z"
        },
        "trusted": true,
        "id": "oTN4ZqznmEuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ = {\"Sentence\": [], 'class': []}\n",
        "for text, cls in test_data:\n",
        "  test_[\"Sentence\"].append(text)\n",
        "  test_[\"class\"].append(cls)\n",
        "\n",
        "train_ = {\"Sentence\": [], 'class': []}\n",
        "for text, cls in train_data:\n",
        "  train_[\"Sentence\"].append(text)\n",
        "  train_[\"class\"].append(cls)\n",
        "\n",
        "df_train = pd.DataFrame(train_)\n",
        "df_test = pd.DataFrame(test_)\n",
        "df = pd.concat([df_train, df_test])\n",
        "df.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T21:05:56.782434Z",
          "iopub.execute_input": "2024-03-24T21:05:56.782770Z",
          "iopub.status.idle": "2024-03-24T21:05:56.805085Z",
          "shell.execute_reply.started": "2024-03-24T21:05:56.782742Z",
          "shell.execute_reply": "2024-03-24T21:05:56.803968Z"
        },
        "trusted": true,
        "id": "KtJtugTTmEud",
        "outputId": "c8e7219b-cfdc-4433-feb0-e69008a01d33"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(5000, 2)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SwiGLU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SwiGLU, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, gate = torch.split(x, split_size_or_sections=2, dim=-1)\n",
        "        gate = torch.nn.functional.silu(gate)\n",
        "        x = out * gate\n",
        "        return x\n",
        "\n",
        "class CosformerAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    cosformer attention in \"cosFormer: Rethinking Softmax In Attention\"\n",
        "    https://arxiv.org/abs/2202.08791\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        embed_dim,\n",
        "        num_heads,\n",
        "        act_fun,\n",
        "        kdim=None,\n",
        "        vdim=None,\n",
        "        dropout_rate=0.0,\n",
        "        causal=False,\n",
        "        has_outproj=True\n",
        "        # act_fun=\"swiglu\",\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.kdim = kdim if kdim is not None else embed_dim\n",
        "        self.vdim = vdim if kdim is not None else embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.has_outproj = has_outproj\n",
        "        self.act_fun = self.get_act_fun(act_fun)\n",
        "        # q, k, v projection\n",
        "        self.k_proj = nn.Linear(self.kdim, embed_dim)\n",
        "        self.v_proj = nn.Linear(self.vdim, embed_dim)\n",
        "        self.q_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        # outprojection\n",
        "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        # dropout rate\n",
        "        self.dropout_rate = dropout_rate\n",
        "        # causal\n",
        "        self.causal = causal\n",
        "\n",
        "        assert (self.embed_dim % self.num_heads == 0), \"embed_dim must be divisible by num_heads\"\n",
        "\n",
        "    def get_index(self, seq_len):\n",
        "        index = np.pi / 2 * torch.arange(1, seq_len + 1).reshape(1, -1, 1)\n",
        "\n",
        "        return nn.Parameter(index, requires_grad=False)\n",
        "\n",
        "    def get_act_fun(self, act_fun):\n",
        "        if act_fun == \"relu\":\n",
        "            return nn.ReLU()\n",
        "        elif act_fun == \"elu\":\n",
        "            return nn.ELU(inplace=True)\n",
        "        elif act_fun == \"swiglu\":  # Добавляем условие для SwiGLU\n",
        "            return SwiGLU()\n",
        "        elif act_fun == \"silu\":\n",
        "          return nn.SiLU()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        query: torch.Tensor,\n",
        "        key: torch.Tensor = None,\n",
        "        value: torch.Tensor = None,\n",
        "        attn_mask: torch.Tensor = None,\n",
        "        eps: float = 1e-6\n",
        "    ):\n",
        "        \"\"\"Input shape: Sequence x Batch x Embedding\n",
        "        Args:\n",
        "            query (Tensor): `(L, N, E)` where L is the target sequence length, N is the batch size,\n",
        "            E is the embedding dimension.\n",
        "            key (Tensor): `(S, N, E)` where S is the source sequence length, N is the batch size,\n",
        "            E is the embedding dimension.\n",
        "            value (Tensor): `(S, N, E)` where S is the source sequence length, N is the batch size,\n",
        "            E is the embedding dimension.\n",
        "            attn_mask (Optional[Tensor], optional): typically used to implement causal attention,\n",
        "            where the mask prevents the attention from looking forward in time (default: None).\n",
        "        \"\"\"\n",
        "        if key is None:\n",
        "            key = query\n",
        "        if value is None:\n",
        "            value = query\n",
        "\n",
        "        num_heads = self.num_heads\n",
        "        tgt_len, bsz, embed_dim = query.size()\n",
        "        src_len = key.size(0)\n",
        "        head_dim = embed_dim // num_heads\n",
        "\n",
        "        # get q, k, v\n",
        "        # (L, N, E)\n",
        "        q = self.q_proj(query)\n",
        "        # (S, N, E)\n",
        "        k = self.k_proj(key)\n",
        "        # (S, N, E)\n",
        "        v = self.v_proj(value)\n",
        "\n",
        "        # activation\n",
        "        q = self.act_fun(q)\n",
        "        k = self.act_fun(k)\n",
        "\n",
        "        # multihead reshape\n",
        "        # (N * h, L, d)\n",
        "        q = q.contiguous().view(-1, bsz * num_heads, head_dim).transpose(0, 1)\n",
        "        # (N * h, S, d)\n",
        "        k = k.contiguous().view(-1, bsz * num_heads, head_dim).transpose(0, 1)\n",
        "        # (N * h, S, d)\n",
        "        v = v.contiguous().view(-1, bsz * num_heads, head_dim).transpose(0, 1)\n",
        "\n",
        "        # cos transform\n",
        "        m = max(src_len, tgt_len)\n",
        "        # get index and send to cuda\n",
        "        weight_index = self.get_index(m).to(q)\n",
        "        # (N * h, L, 2 * d)\n",
        "        q_ = torch.cat([q * torch.sin(weight_index[:, :tgt_len, :] / m), q * torch.cos(weight_index[:, :tgt_len, :] / m)], dim=-1)\n",
        "        # (N * h, S, 2 * d)\n",
        "        k_ = torch.cat([k * torch.sin(weight_index[:, :src_len, :] / m), k * torch.cos(weight_index[:, :src_len, :] / m)], dim=-1)\n",
        "\n",
        "        if self.causal:\n",
        "            # Need to improve speed!\n",
        "            # (N * h, L, 2 * d) (N * h, L, d) -> (N * h, L, h, 2 * d, d)\n",
        "            kv_ = torch.einsum(\"nld,nlm->nldm\", k_, v)\n",
        "            # (N * h, L, 2 * d, d) -> (N * h, L, 2 * d, d)\n",
        "            kv_cum = torch.cumsum(kv_, dim=1)\n",
        "            # (N * h, L, 2 * d) (N * h, L, 2 * d, d) -> (N * h, L, d)\n",
        "            qkv = torch.einsum(\"nld,nldm->nlm\", q_, kv_cum)\n",
        "            # (N * h, L, 2 * d) -> (N * h, L, 2 * d)\n",
        "            k_cum = torch.cumsum(k_, dim=1)\n",
        "            # (N * h, L, 2 * d) (N * h, L, 2 * d) -> (N * h, L)\n",
        "            denom = torch.clamp_min(torch.einsum(\"nlm,nlm->nl\", q_, k_cum), eps)\n",
        "            # (N * h, L, d) (N * h, L, 1) -> (N * h, L, d)\n",
        "            attn_output = qkv / denom.unsqueeze(-1)\n",
        "            # (N * h, L, d) -> (L, N * h, d) -> (L, N, E)\n",
        "            attn_output = attn_output.transpose(0, 1).contiguous().view(tgt_len, bsz, -1)\n",
        "        else:\n",
        "            # (N * h, L, 2 * d) (N * h, L, d) -> (N * h, 2 * d, d)\n",
        "            kv_ = torch.einsum('nld,nlm->ndm', k_, v)\n",
        "            # (N * h, L, 2 * d) (N * h, 2 * d) -> (N * h, L)\n",
        "            z_ = 1 / torch.clamp_min(torch.einsum('nld,nd->nl', q_, torch.sum(k_, axis=1)), eps)\n",
        "            # (N * h, L, 2 * d) (N * h, d, 2 * d) (N * h, L) -> (N * h, L, d)\n",
        "            attn_output = torch.einsum('nld,ndm,nl->nlm', q_, kv_, z_)\n",
        "            # (N * h, L, d) -> (L, N * h, d) -> (L, N, E)\n",
        "            attn_output = attn_output.transpose(0, 1).contiguous().view(tgt_len, bsz, -1)\n",
        "        # L, N, E\n",
        "        if self.has_outproj:\n",
        "            attn_output = self.out_proj(attn_output)\n",
        "\n",
        "        return attn_output\n",
        "\n",
        "class ReluBERT(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(ReluBERT, self).__init__()\n",
        "        #self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.bert =  RobertaModel.from_pretrained(\"FacebookAI/roberta-base\")\n",
        "        # self.attention = nn.MultiheadAttention(embed_dim=self.bert.config.hidden_size,\n",
        "        #                                 num_heads=self.bert.config.num_attention_heads)\n",
        "        self.attention = CosformerAttention(embed_dim=self.bert.config.hidden_size,\n",
        "                                            num_heads=self.bert.config.num_attention_heads,\n",
        "                                            act_fun='relu')\n",
        "        self.dropout = nn.Dropout(self.bert.config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class EluBERT(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(EluBERT, self).__init__()\n",
        "        #self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.bert =  RobertaModel.from_pretrained(\"FacebookAI/roberta-base\")\n",
        "        # self.attention = nn.MultiheadAttention(embed_dim=self.bert.config.hidden_size,\n",
        "        #                                 num_heads=self.bert.config.num_attention_heads)\n",
        "        self.attention = CosformerAttention(embed_dim=self.bert.config.hidden_size,\n",
        "                                            num_heads=self.bert.config.num_attention_heads,\n",
        "                                            act_fun='elu')\n",
        "        self.dropout = nn.Dropout(self.bert.config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class SwigluBERT(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(SwigluBERT, self).__init__()\n",
        "        #self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.bert =  RobertaModel.from_pretrained(\"FacebookAI/roberta-base\")\n",
        "        # self.attention = nn.MultiheadAttention(embed_dim=self.bert.config.hidden_size,\n",
        "        #                                 num_heads=self.bert.config.num_attention_heads)\n",
        "        self.attention = CosformerAttention(embed_dim=self.bert.config.hidden_size,\n",
        "                                            num_heads=self.bert.config.num_attention_heads,\n",
        "                                            act_fun='swiglu')\n",
        "        self.dropout = nn.Dropout(self.bert.config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class SiluBERT(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(SiluBERT, self).__init__()\n",
        "        #self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.bert =  RobertaModel.from_pretrained(\"FacebookAI/roberta-base\")\n",
        "        # self.attention = nn.MultiheadAttention(embed_dim=self.bert.config.hidden_size,\n",
        "        #                                 num_heads=self.bert.config.num_attention_heads)\n",
        "        self.attention = CosformerAttention(embed_dim=self.bert.config.hidden_size,\n",
        "                                            num_heads=self.bert.config.num_attention_heads,\n",
        "                                            act_fun='silu')\n",
        "        self.dropout = nn.Dropout(self.bert.config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class VanillaBERT(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(VanillaBERT, self).__init__()\n",
        "        #self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.bert =  RobertaModel.from_pretrained(\"FacebookAI/roberta-base\")\n",
        "        # self.attention = nn.MultiheadAttention(embed_dim=self.bert.config.hidden_size,\n",
        "        #                                 num_heads=self.bert.config.num_attention_heads)\n",
        "        self.attention = nn.MultiheadAttention(self.bert.config.hidden_size,\n",
        "                                            self.bert.config.num_attention_heads)\n",
        "        self.dropout = nn.Dropout(self.bert.config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader, loss, optimizer, scheduler, num_epochs):\n",
        "    model.train()\n",
        "    total_train_time = 0.0\n",
        "    total_val_time = 0.0\n",
        "    avg_train_loss = 0.0\n",
        "    val_accuracy = 0.0\n",
        "    total_val_time = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "        total_loss = 0.0\n",
        "        for batch in train_dataloader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, labels = batch[:2]\n",
        "\n",
        "            attention_mask = (input_ids != tokenizer.pad_token_id).float()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "\n",
        "            loss_comp = loss(outputs, labels)\n",
        "            total_loss += loss_comp.item()\n",
        "            loss_comp.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Average Training Loss: {avg_train_loss}\")\n",
        "        total_train_time += time.time() - start_time\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        val_preds = []\n",
        "        val_true = []\n",
        "        start_time = time.time()\n",
        "        for batch in val_dataloader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, labels = batch[:2]\n",
        "\n",
        "            attention_mask = (input_ids != tokenizer.pad_token_id).float()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(input_ids, attention_mask)\n",
        "            preds = torch.argmax(outputs, dim=1).cpu().numpy().tolist()\n",
        "            val_preds.extend(preds)\n",
        "            val_true.extend(labels.cpu().numpy().tolist())\n",
        "\n",
        "        val_accuracy = accuracy_score(val_true, val_preds)\n",
        "        print(f\"Validation Accuracy: {val_accuracy}\")\n",
        "        total_val_time += time.time() - start_time\n",
        "    avg_train_speed = total_steps / total_train_time\n",
        "    avg_val_speed = total_steps_val / total_val_time\n",
        "    print(f\"Average Training Speed: {avg_train_speed:.2f} steps/sec\")\n",
        "    print(f\"Average Validation Speed: {avg_val_speed:.2f} steps/sec\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T21:05:56.808457Z",
          "iopub.execute_input": "2024-03-24T21:05:56.808815Z",
          "iopub.status.idle": "2024-03-24T21:05:56.867659Z",
          "shell.execute_reply.started": "2024-03-24T21:05:56.808787Z",
          "shell.execute_reply": "2024-03-24T21:05:56.866597Z"
        },
        "trusted": true,
        "id": "qlW2aaJumEud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T21:05:56.869103Z",
          "iopub.execute_input": "2024-03-24T21:05:56.869416Z",
          "iopub.status.idle": "2024-03-24T21:05:58.015627Z",
          "shell.execute_reply.started": "2024-03-24T21:05:56.869390Z",
          "shell.execute_reply": "2024-03-24T21:05:58.014438Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "6adf5ba280b144e7a6b4eb48a5ba687e",
            "50cd14f35ef84f78a73062c5368eaff8",
            "9bf8449aa6784b4aa0e9851b98c7b9fb",
            "5678cb086b2248e89d2f35b4f6705af0",
            "e95a04b91aa7447b9ad7e9817acab668"
          ]
        },
        "id": "deHkXYxzmEue",
        "outputId": "b26b15a9-9ec1-4b07-9c3f-d432fbaa9166"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "cuda\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6adf5ba280b144e7a6b4eb48a5ba687e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50cd14f35ef84f78a73062c5368eaff8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bf8449aa6784b4aa0e9851b98c7b9fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5678cb086b2248e89d2f35b4f6705af0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e95a04b91aa7447b9ad7e9817acab668"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = list(df['class'])  # labels\n",
        "\n",
        "max_seq_length = 300\n",
        "\n",
        "tokenized_texts = [tokenizer.encode(text, add_special_tokens=True, max_length=max_seq_length, truncation=True) for text in list(df.Sentence)]\n",
        "\n",
        "max_len = max(len(text) for text in tokenized_texts)\n",
        "padded_texts = [text + [0]*(max_len - len(text)) for text in tokenized_texts]\n",
        "\n",
        "input_ids = torch.tensor(padded_texts)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "train_inputs, val_inputs, train_labels, val_labels = train_test_split(input_ids, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(train_inputs, train_labels)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataset = torch.utils.data.TensorDataset(val_inputs, val_labels)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T21:05:58.017276Z",
          "iopub.execute_input": "2024-03-24T21:05:58.017689Z",
          "iopub.status.idle": "2024-03-24T21:06:04.344929Z",
          "shell.execute_reply.started": "2024-03-24T21:05:58.017653Z",
          "shell.execute_reply": "2024-03-24T21:06:04.343831Z"
        },
        "trusted": true,
        "id": "3mBKpYSmmEue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elu_model = EluBERT(num_labels=2)\n",
        "\n",
        "elu_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = AdamW(elu_model.parameters(), lr=2e-5)\n",
        "total_steps = len(train_dataloader) * 5\n",
        "total_steps_val = len(val_dataloader) * 5\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T21:06:04.346221Z",
          "iopub.execute_input": "2024-03-24T21:06:04.346509Z",
          "iopub.status.idle": "2024-03-24T21:06:04.351165Z",
          "shell.execute_reply.started": "2024-03-24T21:06:04.346485Z",
          "shell.execute_reply": "2024-03-24T21:06:04.350128Z"
        },
        "trusted": true,
        "id": "FEXyXVxXmEuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(elu_model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, num_epochs=5)"
      ],
      "metadata": {
        "id": "T2_teYjemEuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "swiglu_model = SwigluBERT(num_labels=2)\n",
        "\n",
        "swiglu_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = AdamW(swiglu_model.parameters(), lr=2e-5)\n",
        "total_steps = len(train_dataloader) * 5\n",
        "total_steps_val = len(val_dataloader) * 5\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T21:06:04.352575Z",
          "iopub.execute_input": "2024-03-24T21:06:04.352914Z",
          "iopub.status.idle": "2024-03-24T21:06:07.902009Z",
          "shell.execute_reply.started": "2024-03-24T21:06:04.352880Z",
          "shell.execute_reply": "2024-03-24T21:06:07.901065Z"
        },
        "trusted": true,
        "id": "-m4bTVTimEuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(swiglu_model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, num_epochs=5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T21:06:07.903335Z",
          "iopub.execute_input": "2024-03-24T21:06:07.903645Z",
          "iopub.status.idle": "2024-03-24T21:23:50.758744Z",
          "shell.execute_reply.started": "2024-03-24T21:06:07.903619Z",
          "shell.execute_reply": "2024-03-24T21:23:50.757703Z"
        },
        "trusted": true,
        "id": "ZtY18W2ymEuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relu_model = ReluBERT(num_labels=2)\n",
        "\n",
        "relu_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = AdamW(relu_model.parameters(), lr=2e-5)\n",
        "total_steps = len(train_dataloader) * 5\n",
        "total_steps_val = len(val_dataloader) * 5\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T20:12:45.973931Z",
          "iopub.execute_input": "2024-03-24T20:12:45.974312Z",
          "iopub.status.idle": "2024-03-24T20:12:46.546833Z",
          "shell.execute_reply.started": "2024-03-24T20:12:45.974283Z",
          "shell.execute_reply": "2024-03-24T20:12:46.545924Z"
        },
        "trusted": true,
        "id": "81SIH6yGmEuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(relu_model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, num_epochs=5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T20:12:48.580667Z",
          "iopub.execute_input": "2024-03-24T20:12:48.581069Z",
          "iopub.status.idle": "2024-03-24T20:31:10.798429Z",
          "shell.execute_reply.started": "2024-03-24T20:12:48.581039Z",
          "shell.execute_reply": "2024-03-24T20:31:10.797310Z"
        },
        "trusted": true,
        "id": "9BpaOI2UmEuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "silu_model = SiluBERT(num_labels=2)\n",
        "\n",
        "silu_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = AdamW(silu_model.parameters(), lr=2e-5)\n",
        "total_steps = len(train_dataloader) * 5\n",
        "total_steps_val = len(val_dataloader) * 5\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T19:53:22.070263Z",
          "iopub.execute_input": "2024-03-24T19:53:22.071179Z",
          "iopub.status.idle": "2024-03-24T19:53:22.710021Z",
          "shell.execute_reply.started": "2024-03-24T19:53:22.071129Z",
          "shell.execute_reply": "2024-03-24T19:53:22.709106Z"
        },
        "trusted": true,
        "id": "QWoW6bUXmEug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(silu_model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, num_epochs=5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T19:53:26.559260Z",
          "iopub.execute_input": "2024-03-24T19:53:26.560404Z",
          "iopub.status.idle": "2024-03-24T20:11:44.001134Z",
          "shell.execute_reply.started": "2024-03-24T19:53:26.560367Z",
          "shell.execute_reply": "2024-03-24T20:11:44.000112Z"
        },
        "trusted": true,
        "id": "m5GcN593mEug"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}